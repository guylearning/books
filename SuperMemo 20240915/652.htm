<html>

<head>
<meta http-equiv="description" content="SuperMemo Collection: (((backup of mindx created on 2024-09-15 23-55-25))), Page: Personal Memory Systems More Broadly">
<meta http-equiv="keywords" content="SuperMemo, (((backup of mindx created on 2024-09-15 23-55-25))), Personal Memory Systems More Broadly">
<meta name="GENERATOR" content="SuperMemo for Windows (Build 18.05)">
<title>(((backup of mindx created on 2024-09-15 23-55-25))): Personal Memory Systems More Broadly (SuperMemo collection)</title>
</head>

<body>

<p align="center"><b><font size="5">(((backup of mindx created on 2024-09-15 23-55-25))): Personal Memory Systems More Broadly </font></b><br>(3 elements)</p>
<a name="TopOfPages"> </a>
<b>Contents:</b>
<div align="center">
<center>
<table border="1" cellpadding="5" cellspacing="5" width="100%" bgcolor="#FFCCFF">
<tr>
<td width="100%">
  <a href="index.htm">Root</a> <a href="653.htm"> - Next</a> - <a href="663.htm">Previous</a> - <a href="263.htm">Parent</a> - <a href="653.htm">Next sibling</a> - <a href="651.htm">Previous sibling</a>
<font size="2">
<ul>
<li><a href="index.htm">MindX</a></li>
<ul>
<li><a href="3.htm">Explor</a></li>
<ul>
<li><a href="90.htm">Learning Lab</a></li>
<ul>
<li><a href="234.htm">SuperMemo</a></li>
<ul>
<li><a href="263.htm">Augmenting Long-term Memory</a></li>
<ul>
<li>This page: Personal Memory Systems More Broadly</li>
<ol>
<li>How important is long-term memory, anyway?. Long-term memory is sometimes disparaged. It's common for people to denigrate “rote memory”, especially in the classroom. I've . (see <a href="#1186">below)</a>
<li>Distributed practice. Why does Anki work? In this section we briefly look at one of the key underlying ideas from cognitive science, known as distributed practice. Suppose . (see <a href="#1187">below)</a>
<li>On the role of cognitive science in the design of systems to augment cognition. Since Ebbinghaus, there's been thousands of studies of different variations of distributed . (see <a href="#1188">below)</a>
</ol>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</font>
</td>
</tr>
</table>
</center>
</div>

<P align="center"><b><a name="1186">Topic #1,186: How important is long-term memory, anyway?. Long-term memory is sometimes disparaged. It's common for people to denigrate &#8220;rote memory&#8221;, especially in the classroom. I've .</a></P>
<div align="center">
<center>
<table border="1" cellpadding="5" cellspacing="5" width="100%" bgcolor="#99CCFF">
<tr>
<td bordercolor="#0066FF">
<strong><font color="blue">Personal Memory Systems More Broadly : </font></strong><H3>How important is long-term memory, anyway?</H3>
<P>Long-term memory is sometimes disparaged. It's common for people to denigrate &#8220;rote memory&#8221;, especially in the classroom. I've heard from many people that they dropped some class &#8211; organic chemistry is common &#8211; because it was &#8220;just a bunch of facts, and I wanted something involving more understanding&#8221;. </P>
<P>I won't defend bad classroom teaching, or the way organic chemistry is often taught. But it's a mistake to underestimate the importance of memory. I used to believe such tropes about the low importance of memory. But I now believe memory is at the foundation of our cognition. </P>
<P>There are two main reasons for this change, one a personal experience, the other based on evidence from cognitive science. </P>
<P>Let me begin with the personal experience. </P>
<P>Over the years, I've often helped people learn technical subjects such as quantum mechanics. Over time you come to see patterns in how people get stuck. One common pattern is that people think they're getting stuck on esoteric, complex issues. But when you dig down it turns out they're having a hard time with basic notation and terminology. It's difficult to understand quantum mechanics when you're unclear about every third word or piece of notation! Every sentence is a struggle. </P>
<P>It's like they're trying to compose a beautiful sonnet in French, but only know 200 words of French. They're frustrated, and think the trouble is the difficulty of finding a good theme, striking sentiments and images, and so on. But really the issue is that they have only 200 words with which to compose. </P>
<P>My somewhat pious belief was that if people focused more on remembering the basics, and worried less about the &#8220;difficult&#8221; high-level issues, they'd find the high-level issues took care of themselves. </P>
<P>But while I held this as a strong conviction about other people, I never realized it also applied to me. And I had no idea at all how strongly it applied to me. Using Anki to read papers in new fields disabused me of this illusion. I found it almost unsettling how much easier Anki made learning such subjects. I now believe memory of the basics is often the single largest barrier to understanding. If you have a system such as Anki for overcoming that barrier, then you will find it much, much easier to read into new fields. </P>
<P>This experience of how much easier Anki made learning a new technical field greatly increased my visceral appreciation for the importance of memory. </P>
<P>There are also many results from cognitive science on the key role memory plays in cognition. </P>
<P>One striking line of work was done (separately) by the researchers Adriaan de Groot and Herbert Simon, studying how people acquire expertise, focusing particularly on chess*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* See, for instance, Herbert A. Simon, <A href="https://augmentingcognition.com/assets/Simon1974.pdf">How Big is a Chunk?</A>, Science (1974), and Adriaan de Groot, <EM>Thought and Choice in Chess</EM>, Amsterdam University Press (2008, reprinted from 1965).</SPAN>. They found that world-class chess experts saw the board differently to beginners. A beginner would see &#8220;a pawn here, a rook there&#8221;, and so on, a series of individual pieces. Masters, by contrast, saw much more elaborate &#8220;chunks&#8221;: combinations of pieces that they recognized as a unit, and were able to reason about at a higher level of abstraction than the individual pieces. </P>
<P>Simon estimated chess masters learn between 25,000 and 100,000 of these chunks during their training, and that learning the chunks was a key element in becoming a first-rate chess player. Such players really see chess positions very differently from beginners. </P>
<P>Why does learning to recognize and reason about such chunks help so much in developing expertise? Here's a speculative, informal model &#8211; as far as I know, it hasn't been validated by cognitive scientists, so don't take it too seriously. I'll describe it in the context of mathematics, instead of chess, since mathematics is an area where I have experience talking with people at all ranges of ability, from beginners to accomplished professional mathematicians. </P>
<P>Many people's model of accomplished mathematicians is that they are astoundingly bright, with very high IQs, and the ability to deal with very complex ideas in their mind. A common perception is that their smartness gives them the ability to deal with very complex ideas. Basically, they have a higher horsepower engine. </P>
<P>It's true that top mathematicians are usually very bright. But here's a different explanation of what's going on. It's that, per Simon, many top mathematicians have, through hard work, internalized many more complex mathematical chunks than ordinary humans. And what this means is that mathematical situations which seem very complex to the rest of us seem very simple to them. So it's not that they have a higher horsepower mind, in the sense of being able to deal with more complexity. Rather, their prior learning has given them better chunking abilities, and so situations most people would see as complex they see as simple, and they find it much easier to reason about. </P>
<P>Now, the concept of chunks used by Simon in his study of chess players actually came from a famous 1956 paper by George Miller, &#8220;The Magical Number Seven, Plus or Minus Two&#8221;*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* George A. Miller, <A href="http://psychclassics.yorku.ca/Miller/">The Magical Number Seven, Plus or Minus Two: Some Limits on our Capacity for Processing Information</A> (1956).</SPAN>. Miller argued that the capacity of working memory is roughly seven chunks. In fact, it turns out that there is variation in that number from person to person, and a substantial correlation between the capacity of an individual's working memory and their general intellectual ability (IQ)*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* A review of the correlation may be found in Phillip L. Ackerman, Margaret E. Beier, and Mary O. Boyle, <A href="https://augmentingcognition.com/assets/Ackerman2006.pdf">Working Memory and Intelligence: The Same or Different Constructs?</A> Psychological Bulletin (2006).</SPAN>. Typically, the better your working memory, the higher your IQ, and vice versa. </P>
<P>Exactly what Miller meant by chunks he left somewhat vague, writing: </P>
<BLOCKQUOTE>The contrast of the terms bit and chunk also serves to highlight the fact that we are not very definite about what constitutes a chunk of information. For example, the memory span of five words that Hayes obtained&#8230; might just as appropriately have been called a memory span of 15 phonemes, since each word had about three phonemes in it. Intuitively, it is clear that the subjects were recalling five words, not 15 phonemes, but the logical distinction is not immediately apparent. We are dealing here with a process of organizing or grouping the input into familiar units or chunks, and a great deal of learning has gone into the formation of these familiar units. </BLOCKQUOTE>
<P>Put another way, in Miller's account the chunk was effectively the <EM>basic unit</EM> of working memory. And so Simon and his collaborators were studying the basic units used in the working memory of chess players. If those chunks were more complex, then that meant a player's working memory had a higher effective capacity. In particular, someone with a lower IQ but able to call on more complex chunks would be able to reason about more complex situations than someone with a higher IQ but less complex internalized chunks. </P>
<P>In other words, having more chunks memorized in some domain is somewhat like an effective boost to a person's IQ in that domain. </P>
<P>Okay, that's a speculative informal model. Regardless of whether it's correct, it does seem that internalizing high-level chunks is a crucial part of acquiring expertise. However, that doesn't then necessarily imply that the use of systems such as Anki will speed up acquisition of such chunks. It's merely an argument that long-term memory plays a crucial role in the acquisition of some types of expertise. Still, it seems plausible that regular use of systems such as Anki may speed up the acquisition of the high-level chunks used by experts*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* To determine this it would help to understand exactly how these chunks arise. That still seems to be poorly understood. I wouldn't be surprised if it involved considerable analysis and problem-solving, in addition to long-term memory.</SPAN>. And that those chunks are then at the heart of effective cognition, including our ability to understand, to problem solve, and to create.
</td>
</tr>
</table>
</center>
</div>
<hr>
<P align="center"><b><a name="1187">Topic #1,187: Distributed practice. Why does Anki work? In this section we briefly look at one of the key underlying ideas from cognitive science, known as distributed practice. Suppose .</a> (<a href="#TopOfPages"><font size="1">top</font></a></b>)</P>
<div align="center">
<center>
<table border="1" cellpadding="5" cellspacing="5" width="100%" bgcolor="#99CCFF">
<tr>
<td bordercolor="#0066FF">
<strong><font color="blue">Personal Memory Systems More Broadly : </font></strong>

<P></P>
<H3>Distributed practice</H3>
<P>Why does Anki work? In this section we briefly look at one of the key underlying ideas from cognitive science, known as <EM>distributed practice</EM>. </P>
<P>Suppose you're introduced to someone at a party, and they tell you their name. If you're paying attention, and their name isn't too unusual, you'll almost certainly remember their name 20 seconds later. But you're more likely to have forgotten their name in an hour, and more likely still to have forgotten their name in a month. </P>
<P>That is, memories decay. This isn't news! But the great German psychologist Hermann Ebbinghaus had the good idea of studying memory decay systematically and quantitatively*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* Hermann Ebbinghaus, <A href="http://psychclassics.yorku.ca/Ebbinghaus/index.htm">Memory: A Contribution to Experimental Psychology</A> (1885). A recent replication of Ebbinghaus's results may be found in: Jaap M. J. Murre and Joeri Dros, <A href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0120644">Replication and Analysis of Ebbinghaus' Forgetting Curve</A> (2015).</SPAN>. In particular, he was interested in how quickly memories decay, and what causes the decay. To study this, Ebbinghaus memorized strings of nonsense syllables &#8211; things like &#8220;fim&#8220; and &#8220;pes&#8221; &#8211; and later tested himself, recording how well he retained those syllables after different time intervals. </P>
<P>Ebbinghaus found that the probability of correctly recalling an item declined (roughly) exponentially with time. Today, this is called the <EM>Ebbinghaus forgetting curve</EM>: </P><img src="https://augmentingcognition.com/assets/Ebbinghaus.png"> 
<P>What determines the steepness of the curve, i.e., how quickly memories decay? In fact, the steepness depends on many things. For instance, it may be steeper for more complex or less familiar concepts. You may find it easier to remember a name that sounds similar to names you've heard before: say, Richard Hamilton, rather than Suzuki Harunobu. So they'd have a shallower curve. Similarly, you may find it easier to remember something visual than verbal. Or something verbal rather than a motor skill. And if you use more elaborate ways of remembering &#8211; mnemonics, for instance, or just taking care to connect an idea to other things you already know &#8211; you may be able to flatten the curve out*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* Although this expansion is much studied, there is surprisingly little work building detailed predictive models of the expansion. An exception is: Burr Settles and Brendan Meeder, <A href="https://augmentingcognition.com/assets/Settles2016.pdf">A Trainable Spaced Repetition Model for Language Learning</A> (2016). This paper builds a regression model to predict the decay rate of student memory on Duolingo, the online language learning platform. The result was not only better prediction of decay rates, but also improved Duolingo student engagement.</SPAN>. </P>
<P>Suppose you're introduced to a person at a party, and then don't think about their name for 20 minutes. But then you need to introduce them to someone else, and so need to bring it to mind. Immediately after that, your probability of recall will again be very high. Ebbinghaus's research suggested that the probability will decay exponentially after the re-test, but the rate of decay will be slower than it was initially. In fact, subsequent re-tests will slow the decay still more, a gradually flattening out of the decay curve as the memory is consolidated through multiple recall events: </P><img src="https://augmentingcognition.com/assets/Ebbinghaus_repeat.png"> 
<P>This gradual increase in decay time underlies the design of Anki and similar memory systems. It's why Anki gradually expands the time periods between testing. </P>
<P>These phenomena are part of a broader set of ideas which have been extensively studied by scientists. There are several related terms used for this set of phenomena, but we'll use the phrase &#8220;distributed practice&#8221;, meaning practice which is distributed in time, ideally in a way designed to maximally promote retention. This is in contrast to cramming, often known as massed practice, where people try to fit all their study into just one session, relying on repetition.
</td>
</tr>
</table>
</center>
</div>
<hr>
<P align="center"><b><a name="1188">Topic #1,188: On the role of cognitive science in the design of systems to augment cognition. Since Ebbinghaus, there's been thousands of studies of different variations of distributed .</a> (<a href="#TopOfPages"><font size="1">top</font></a></b>)</P>
<div align="center">
<center>
<table border="1" cellpadding="5" cellspacing="5" width="100%" bgcolor="#99CCFF">
<tr>
<td bordercolor="#0066FF">
<strong><font color="blue">Personal Memory Systems More Broadly : </font></strong>

<P></P>
<H3>On the role of cognitive science in the design of systems to augment cognition</H3>
<P>Since Ebbinghaus, there's been thousands of studies of different variations of distributed practice. These studies have taught us a great deal about the behavior of long-term memory. Most of all, they show emphatically that distributed practice outperforms massed practice*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* Many experiments also try to assess participants' perception of the effectiveness of massed practice versus distributed practice. Remarkably, they often believe that massed practice is more effective, despite the fact that it is reliably outperformed by distributed practice.</SPAN>. It's tempting to jump into that literature, and to use it as a guide to the design of memory systems*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* Rather than do such a review, let me point to several reviews which serve as useful entry points. Benedict Carey's book &#8220;How We Learn&#8221; (2015) is a good introduction at a popular level. Useful reviews of the distributed practice literature include: Cepeda <EM>et al</EM>, <A href="https://augmentingcognition.com/assets/Cepeda2006.pdf">Distributed Practice in Verbal Recall Tasks: A Review and Quantitative Synthesis</A> (2006); and: Gwern Branwen, <A href="https://www.gwern.net/Spaced-repetition">Spaced-Repetition</A>.</SPAN>. But it's also worth thinking about the limitations of that literature as a guide to the development of systems. </P>
<P>While scientists have done a tremendous number of studies of distributed practice, many fundamental questions about distributed practice remain poorly understood. </P>
<P>We don't understand in detail why exponential decay of memory occurs, or when that model breaks down. We don't have good models of what determines the rate of decay, and why it varies for different types of memories. We don't understand why the decay takes longer after subsequent recalls. And we have little understanding of the best way of expanding the inter-study intervals. </P>
<P>Of course, there are many partial theories to answer these and other fundamental questions. But there's no single, quantitatively predictive, broadly accepted general theory. And so in that sense, we know little about distributed practice, and are probably decades (if not more) away from a reasonably full understanding. </P>
<P>To illustrate this point concretely, let me mention just one example: there are times when our memories don't decay, but get better over time, even when we're not aware of explicit acts of recall. Informally, you may have noticed this in your own life. The psychologist William James made the tongue-in-cheek observation, which he attributed to an unnamed German author, that*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* William James, &#8220;The Principles of Psychology&#8221; (1890).</SPAN> </P>
<BLOCKQUOTE>we learn to swim during the winter and to skate during the summer. </BLOCKQUOTE>
<P>In fact, exactly such an effect was experimentally verified in an 1895 study of Axel Oehrn*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* Axel Oehrn, Experimentelle Studien zur Individualpsychologie (1895).</SPAN>. While subsequent experiments have confirmed this result, it depends sensitively on the type of material being memorized, on the exact time intervals, and many other variables. Now, in some sense this contradicts the Ebbinghaus exponential forgetting curve. In practice, a pretty good heuristic is that the Ebbinghaus curve holds approximately, but there are exceptions, usually over limited times, and for very specific types of materials. </P>
<P>I don't mention this to undermine your belief in the Ebbinghaus model. But rather as a caution: memory is complicated, we don't understand many of the big picture questions well, and we should be careful before we put too much faith in any given model. </P>
<P>With all that said: the basic effects underlying distributed practice and the Ebbinghaus forgetting curve are real, large, and have been confirmed by many experiments. Effects like that discovered by Oehrn are less important by comparison. </P>
<P>This places us in a curious situation: we have enough understanding of memory to conclude that a system like Anki should help a lot. But many of the choices needed in the design of such a system must be made in an <EM>ad hoc</EM> way, guided by intuition and unconfirmed hypotheses. The experiments in the scientific literature do <EM>not</EM> yet justify those design choices. The reason is that those experiments are mostly not intended to address those questions. They'll focus on specific types of information to memorize. Or they'll focus on relatively short periods of time &#8211; memorization over a day or a week, not for years. Such work helps us build a better theory of memory, but it's not necessarily answering the questions designers need to build systems. </P>
<P>As a consequence, system designers must look elsewhere, to informal experiments and theories. Anki, for example, uses a spacing algorithm developed by Piotr Wozniak on the basis of personal experimentation*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* See: Piotr Wozniak, <A href="https://www.supermemo.com/english/algsm11.htm">Repetition spacing algorithm used in SuperMemo 2002 through SuperMemo 2006</A>. Anki uses algorithm SM-2.</SPAN>. Although Wozniak has published a <A href="https://www.supermemo.com/english/publicat.htm">number of papers</A>, they are informal reports, and don't abide by the norms of the conventional cognitive science literature. </P>
<P>In some sense, this is not satisfactory: we don't have a very good understanding of what spacing schedule to use. But a system has to use some schedule, and so designers do the best they can. This seems likely to work much better than naive approaches, but over the long run it'd be good to have an approach based on a detailed theory of human memory. </P>
<P>Now, one response to this is to say that you should design scientifically, and have good experimental evidence for all design choices. I've heard this used as a criticism of the designers of systems such as Anki, that they make too many <EM>ad hoc</EM> guesses, not backed by a systematic scientific understanding. </P>
<P>But what are they supposed to do? Wait 50 or 100 years, until those answers are in? Give up design, and become memory scientists for the next 30 years, so they can give properly &#8220;scientific&#8221; answers to all the questions they need answered in the design of their systems? </P>
<P>This isn't the way design works, nor the way it should work. </P>
<P>If designers waited until all the evidence was in, no-one would ever design anything. In practice, what you want is bold, imaginative design, exploring many ideas, but inspired and informed (and not too constrained) by what is known scientifically. Ideally, alongside this there would be a much slower feedback loop, whereby design choices would suggest questions about memory, which would lead to new scientific experiments, and thence to an improved understanding of memory, which would in turn suggest new avenues for design. </P>
<P>Such a balance is not easy to achieve. The human-computer interaction (HCI) community has tried to achieve it in the systems they build, not just for memory, but for augmenting human cognition in general. But I don't think it's worked so well. It seems to me that they've given up a lot of boldness and imagination and aspiration in their design*<SPAN class=marginnote 72%? LEFT: 148px; WIDTH:>* As an outsider, I'm aware this comment won't make me any friends within the HCI community. On the other hand, I don't think it does any good to be silent, either. When I look at major events within the community, such as the CHI conference, the overwhelming majority of papers seem timid when compared to early work on augmentation. It's telling that publishing conventional static papers (pdf, not even interactive JavaScript and HTML) is still so central to the field. </SPAN>. At the same time, they're not doing full-fledged cognitive science either &#8211; they're not developing a detailed understanding of the mind. Finding the right relationship between imaginative design and cognitive science is a core problem for work on augmentation, and it's not trivial. </P>
<P>In a similar vein, it's tempting to imagine cognitive scientists starting to build systems. While this may sometimes work, I think it's unlikely to yield good results in most cases. Building effective systems, even prototypes, is difficult. Cognitive scientists for the most part lack the skills and the design imagination to do it well. </P>
<P>This suggests to me the need for a separate field of human augmentation. That field will take input from cognitive science. But it will fundamentally be a design science, oriented toward bold, imaginative design, and building systems from prototype to large-scale deployment. </P>
<H3>
</td>
</tr>
</table>
</center>
</div>
<hr>
<div align="center">
<center>
<table border="2" cellpadding="5" cellspacing="5" width="100%" bgcolor="#FFCC66">
<tr>
<td width="100%">
<p><b>About using this material:</b></p>
<p>The best way to <b>learn</b> this material is to use <a href="http://super-memory.com/english/smintro.htm">SuperMemo</a> software.<br>
SuperMemo is the world's leader in accelerated learning technologies
 (see: <a href="http://www.super-memory.com">SuperMemo Website</a>)
<p>
No download URL currently available
</td>
</tr>
<tr>
<td width="100%">
<b>Contact data:</b></p>
<p><b>Author: User of SuperMemo</b><br>
<a href="http://super-memory.com">super-memory.com</a><br>
date: 10/3/2024 10:20:39 AM<br>
Page generated with:<br> SuperMemo 18<br>Build: 18.05 of Oct 29, 2020
</td>
</tr>
<tr>
<td width="100%">
</td>
</tr>
</table>
</center>
</div>
</body>

</html>
