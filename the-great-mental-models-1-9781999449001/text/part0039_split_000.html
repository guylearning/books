<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>The Great Mental Models Vol.1</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<div id="_idContainer369" class="calibre1">
    <h1 class="headings" id="calibre_pb_0">Probabilistic Thinking</h1>

    <p class="calibre2">Probabilistic thinking is essentially trying to estimate, using some tools of math and logic, the likelihood of any specific outcome coming to pass. It is one of the best tools we have to improve the accuracy of our decisions. In a world where each moment is determined by an infinitely complex set of factors, probabilistic thinking helps us identify the most likely outcomes. When we know these our decisions can be more precise and effective.</p>

    <p class="akkurat_regular1">Are you going to get hit by lightning or not?</p>

    <p class="calibre2">Why we need the concept of probabilities at all is worth thinking about. Things either are or are not, right? We either <em class="italic">will</em><em class="italic"> </em>get hit by lightning today or we <em class="italic">won’t.</em> The problem is, we just don’t know until we live out the day. Which doesn’t help us at all when we make our decisions in the morning. The future is far from determined and we can better navigate it by understanding the likelihood of events that could impact us.</p>

    <p class="body">Our lack of perfect information about the world gives rise to all of probability theory, and its usefulness. We know now that the future is inherently unpredictable because not all variables can be known and even the smallest error imaginable in our data very quickly throws off our predictions. The best we can do is estimate the future by generating realistic, useful probabilities. So how do we do that?</p>

    <p class="body">Probability is everywhere, down to the very bones of the world. The probabilistic machinery in our minds—the cut-to-the-quick <em class="italic">heuristics</em> made so famous by the psychologists Daniel Kahneman and Amos Tversky—was evolved by the human species in a time before computers, factories, traffic, middle managers, and the stock market. It served us in a time when human life was about <em class="italic">survival</em>, and still serves us well in that capacity.<span class="footnote_ref2"><a id="ch6-2" href="part0055.html#ch6-link-2" class="calibre5">2</a></span></p>

    <p class="sp">But what about today—a time when, for most of us, survival is not so much the issue? We want to <em class="italic">thrive</em>. We want to compete, and win. Mostly, we want to make good decisions in complex social systems that were not part of the world in which our brains evolved their (quite rational) heuristics.</p>

    <p class="body">For this, we need to consciously add in a needed layer of probability awareness. What is it and how can I use it to my advantage?</p>

    <p class="body">There are three important aspects of probability that we need to explain so you can integrate them into your thinking to get into the ballpark and improve your chances of catching the ball:</p>

    <ol class="akkurat_regular3">
      <li value="1" class="calibre8"><p class="archer1"><span class="akkurat_regular"> Bayesian thinking </span></p></li>

      <li value="2" class="calibre8"><p class="archer1"><span class="akkurat_regular"> Fat-tailed curves</span></p></li>

      <li value="3" class="calibre8"><p class="archer1"><span class="akkurat_regular"> Asymmetries</span></p></li>
    </ol>

    <p class="sp"><span class="akkurat_regular">Thomas Bayes and Bayesian thinking:</span> Bayes was an English minister in the first half of the 18th century, whose most famous work, “An Essay Toward Solving a Problem in the Doctrine of Chances”, was brought to the attention of the Royal Society by his friend Richard Price in 1763—two years after his death. The essay concerned how we should adjust probabilities when we encounter new data, and provided the seeds for the great mathematician Pierre Simon Laplace to develop what we now call Bayes’s Theorem.</p>

    <p class="body">The core of Bayesian thinking (or Bayesian updating, as it can be called) is this: given that we have limited but useful information about the world, and are constantly encountering new information, we should probably take into account what we already know when we learn something new. As much of it as possible. Bayesian thinking allows us to use all relevant prior information<em class="italic"> </em>in making decisions. Statisticians might call it a <em class="italic">base rate</em>, taking in outside information about past situations like the one you’re in.</p>

    <p class="body">Consider the headline “Violent Stabbings on the Rise.” Without Bayesian thinking, you might become genuinely afraid because your chances of being a victim of assault or murder is higher than it was a few months ago. But a Bayesian approach will have you putting this information into the context of what you already know about violent crime.</p>

    <p class="body">You know that violent crime has been declining to its lowest rates in decades. Your city is safer now than it has been since this measurement started. Let’s say your chance of being a victim of a stabbing last year was one in 10,000, or 0.01%. The article states, with accuracy, that violent crime has doubled. It is now two in 10,000, or 0.02%. Is that worth being terribly worried about? The prior information here is key. When we factor it in, we realize that our safety has not really been compromised.</p>

    <p class="body">Conversely, if we look at the diabetes statistics in the United States, our application of prior knowledge would lead us to a different conclusion. Here, a Bayesian analysis indicates you should be concerned. In 1958, 0.93% of the population was diagnosed with diabetes. In 2015 it was 7.4%. When you look at the intervening years, the climb in diabetes diagnosis is steady, not a spike. So the prior relevant data, or priors, indicate a trend that is worrisome.</p>

    <p class="body">It is important to remember that priors themselves are probability estimates. For each bit of prior knowledge, you are not putting it in a binary structure, saying it is true or not. You’re assigning it a probability of being true. Therefore, you can’t let your priors get in the way of processing new knowledge. In Bayesian terms, this is called the likelihood ratio or the Bayes factor. Any new information you encounter that challenges a prior simply means that the probability of that prior being true may be reduced. Eventually some priors are replaced completely. This is an ongoing cycle of challenging and validating what you believe you know. When making uncertain decisions, it’s nearly always a mistake not to ask: What are the relevant priors? What might I already know that I can use to better understand the reality of the situation? <span class="sidebar_marker1">— Sidebar: Conditional Probability</span></p>

    <div class="calibre7" id="calibre_pb_1"></div>
</div>
</body></html>
